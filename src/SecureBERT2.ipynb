{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207d66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ab/empirical/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predictions for [MASK]:\n",
      "→  operating\n",
      "→  Windows\n",
      "→  Linux\n",
      "→  file\n",
      "→  banking\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the SecureBERT 2.0 model and tokenizer\n",
    "model_name = \"cisco-ai/SecureBERT2.0-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "# Example sentence with a [MASK] token\n",
    "text = \"The malware exploits a vulnerability in the [MASK] system.\"\n",
    "\n",
    "# Tokenize the text and get model outputs\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Identify the index of the [MASK] token\n",
    "mask_token_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
    "\n",
    "# Get prediction scores for the [MASK] position only\n",
    "mask_token_logits = outputs.logits[0, mask_token_index, :]\n",
    "\n",
    "# Pick top 5 likely predictions\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "\n",
    "print(\"Top 5 predictions for [MASK]:\")\n",
    "for token in top_5_tokens:\n",
    "    print(f\"→ {tokenizer.decode([token])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980f6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import csv\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from collections import Counter\n",
    "\n",
    "# --- Rule-based IoT classifier ---\n",
    "def classify_cve_iot_category(cve_json):\n",
    "    text_fields = []\n",
    "    try:\n",
    "        cna = cve_json[\"containers\"][\"cna\"]\n",
    "        for desc in cna.get(\"descriptions\", []):\n",
    "            text_fields.append(desc.get(\"value\", \"\").lower())\n",
    "        for aff in cna.get(\"affected\", []):\n",
    "            text_fields.append(aff.get(\"vendor\", \"\").lower())\n",
    "            text_fields.append(aff.get(\"product\", \"\").lower())\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "    text = \" \".join(text_fields)\n",
    "\n",
    "    if any(k in text for k in [\"router\", \"tplink\", \"d-link\", \"asus\", \"home\", \"smart\", \"tv\", \"soho\", \"camera\"]):\n",
    "        return \"H (Home)\"\n",
    "    elif any(k in text for k in [\"plc\", \"scada\", \"industrial\", \"ics\", \"automotive\", \"car\", \"vehicle\", \"sensor\", \"medical\"]):\n",
    "        return \"S (SCADA/Industrial)\"\n",
    "    elif any(k in text for k in [\"server\", \"enterprise\", \"network\", \"switch\", \"firewall\", \"keycloak\", \"vpn\", \"red hat\", \"cisco\", \"juniper\"]):\n",
    "        return \"E (Enterprise)\"\n",
    "    elif any(k in text for k in [\"android\", \"ios\", \"mobile\", \"tablet\", \"smartwatch\", \"phone\"]):\n",
    "        return \"M (Mobile)\"\n",
    "    elif any(k in text for k in [\"windows\", \"linux\", \"ubuntu\", \"intel nuc\", \"pc\", \"laptop\", \"desktop\"]):\n",
    "        return \"P (PC/Server)\"\n",
    "    elif any(k in text for k in [\"printer\", \"copier\", \"projector\", \"multimedia\", \"display\"]):\n",
    "        return \"A (Other Non-Home Appliances)\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "# --- Label normalization ---\n",
    "rule_map = {\n",
    "    \"H (Home)\": \"Home\",\n",
    "    \"S (SCADA/Industrial)\": \"SCADA\",\n",
    "    \"E (Enterprise)\": \"Enterprise\",\n",
    "    \"M (Mobile)\": \"Mobile\",\n",
    "    \"P (PC/Server)\": \"PC\",\n",
    "    \"A (Other Non-Home Appliances)\": \"Other\",\n",
    "    \"Unknown\": \"Unknown\"\n",
    "}\n",
    "\n",
    "# --- SecureBERT 2.0 setup ---\n",
    "model_name = \"cisco-ai/SecureBERT2.0-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "iot_labels = [\"Home\", \"SCADA\", \"Enterprise\", \"Mobile\", \"PC\", \"Other\"]\n",
    "\n",
    "# --- Root folder containing JSONs ---\n",
    "root_folder = Path(\"~/updatOR/data/dataset_fw\").expanduser()\n",
    "json_files = list(root_folder.rglob(\"*.json\"))\n",
    "print(f\"Found {len(json_files)} JSON files.\")\n",
    "\n",
    "# --- Counters ---\n",
    "mismatch_counter = 0\n",
    "rule_counter = Counter()\n",
    "nlp_counter = Counter()\n",
    "\n",
    "# --- CSV output ---\n",
    "output_csv = \"iot_classification_results.csv\"\n",
    "with open(output_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"File\", \"Rule-based\", \"NLP-based\", \"Match\"])\n",
    "\n",
    "    for json_file in json_files:\n",
    "        try:\n",
    "            with open(json_file) as f:\n",
    "                cve_data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {json_file}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # --- Rule-based classification ---\n",
    "        rule_class = classify_cve_iot_category(cve_data)\n",
    "        rule_norm = rule_map.get(rule_class, \"Unknown\")\n",
    "        rule_counter[rule_norm] += 1\n",
    "\n",
    "        # --- Extract description ---\n",
    "        cve_description = \"\"\n",
    "        try:\n",
    "            descriptions = cve_data[\"containers\"][\"cna\"].get(\"descriptions\", [])\n",
    "            if descriptions:\n",
    "                cve_description = descriptions[0].get(\"value\", \"\")\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "        # --- NLP-based classification ---\n",
    "        text = f\"This vulnerability affects a {tokenizer.mask_token} device. {cve_description}\"\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs).logits\n",
    "\n",
    "        mask_index = (inputs.input_ids == tokenizer.mask_token_id).nonzero(as_tuple=True)[1]\n",
    "\n",
    "        # --- Score each label (support multi-token labels) ---\n",
    "        label_scores = {}\n",
    "        for label in iot_labels:\n",
    "            label_tokens = tokenizer.tokenize(label)\n",
    "            token_ids = tokenizer.convert_tokens_to_ids(label_tokens)\n",
    "            score = outputs[0, mask_index, token_ids].sum().item() if len(token_ids) > 0 else float('-inf')\n",
    "            label_scores[label] = score\n",
    "\n",
    "        ml_class = max(label_scores, key=label_scores.get)\n",
    "        nlp_counter[ml_class] += 1\n",
    "\n",
    "        match_status = \"MATCH\" if ml_class == rule_norm else \"DIFFER\"\n",
    "        if match_status == \"DIFFER\":\n",
    "            mismatch_counter += 1\n",
    "\n",
    "        print(f\"{json_file.name}: Rule={rule_class}, NLP={ml_class}, {match_status}\")\n",
    "\n",
    "        # --- Write to CSV ---\n",
    "        writer.writerow([json_file.name, rule_class, ml_class, match_status])\n",
    "\n",
    "# --- Print summary ---\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(f\"Total mismatches: {mismatch_counter}\")\n",
    "print(\"Rule-based category counts:\", dict(rule_counter))\n",
    "print(\"NLP-based category counts:\", dict(nlp_counter))\n",
    "print(f\"\\nAll results saved to {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
